"""main.py

Archivo principal que arranca la aplicaci√≥n FastAPI.

Responsabilidades:
    - Cargar embeddings locales (RAG simple / placeholder).
    - Exponer endpoint /ask (consulta con LLM Groq o modo placeholder).
    - Incluir routers modulares: noticias, storage, oportunidades.
    - Ingestar mensajes externos (/ingest/messages) para futura indexaci√≥n.
    - Webhook de verificaci√≥n y recepci√≥n de WhatsApp Cloud API.

NOTA: A futuro podr√≠as mover storage y oportunidades a routers separados, igual que news.
"""

# ============================= Imports base =============================
import os  # Variables de entorno, rutas.
import json  # Lectura/escritura de ficheros JSON.
import time  # Marcas de tiempo epoch para mensajes.
import numpy as np  # Operaciones vectoriales (similaridad embeddings).
from fastapi import FastAPI, Request, Response, Query as FastAPIQuery, HTTPException  # Framework web.
from fastapi.middleware.cors import CORSMiddleware  # (Si quisieras habilitar CORS granular; aqu√≠ no configurado expl√≠cito).
from pydantic import BaseModel  # Modelos de entrada/salida simples.
from sentence_transformers import SentenceTransformer  # Modelo de embeddings local.
import requests  # Llamadas HTTP a Groq.
from typing import List  # Tipado de listas.
from .stores import news_store  # Import para inicializar tabla noticias.
from .routers import news as news_router  # Router noticias.
from .routers import storage as storage_router  # Nuevo router storage.
from .routers import oportunidades as oportunidades_router  # Nuevo router oportunidades.
from .core.security import check_admin  # Verificaci√≥n de token admin (centralizado).
from duckduckgo_search import DDGS  # B√∫squeda web ligera contextual.
import random  # Selecci√≥n de respuestas placeholder.

# ============================= Configuraci√≥n base RAG / LLM =============================
BASE_DIR = os.path.dirname(os.path.dirname(__file__))  # Ruta ra√≠z del m√≥dulo backend/asistente-rag.
FRAGMENTS_DIR = os.path.join(BASE_DIR, "fragments")  # Carpeta donde se guardan fragmentos y embeddings.
MESSAGES_DIR = os.path.join(BASE_DIR, "data_ingest", "messages")  # Carpeta para almacenar messages ingresados.
os.makedirs(FRAGMENTS_DIR, exist_ok=True)  # Crea carpeta si no existe.
os.makedirs(MESSAGES_DIR, exist_ok=True)  # Crea carpeta si no existe.
EMBEDDINGS_PATH = os.path.join(FRAGMENTS_DIR, "fragments_embedded.json")  # Archivo con embeddings precomputados.
MODEL_EMBED = "all-MiniLM-L6-v2"  # Nombre del modelo SentenceTransformer usado para generar embeddings.
GROQ_API_KEY = os.getenv("GROQ_API_KEY", "")  # API key para Groq; si vac√≠o se responde mensaje de falta config.
GROQ_URL = "https://api.groq.com/openai/v1/chat/completions"  # Endpoint Groq compatible OpenAI.
GROQ_MODEL = "llama3-8b-8192"  # Modelo LLM elegido.
TOP_K = 4  # Cu√°ntos fragmentos de contexto local incluimos.
PLACEHOLDER_MODE = os.getenv("CHATBOT_PLACEHOLDER", "1")  # Si "1": no llama Groq, responde frases predefinidas.

PLACEHOLDER_RESPUESTAS = [  # Lista de mensajes aleatorios cuando no se permite acceso a datos/LLM real.
    "No tengo acceso a los datos ahora mismo, los est√°n reorganizando bajo tierra. ‚õèÔ∏è",
    "Los datos est√°n en una fila infinita para validaci√≥n‚Ä¶ sigo esperando. üïí",
    "Estoy mirando estantes vac√≠os: no puedo leer la base todav√≠a. üìö",
    "Mi base de datos est√° tomando vacaciones forzadas. Vuelve luego. üèñÔ∏è",
    "Recalentando servidores imaginarios‚Ä¶ sin datos por ahora. üî•",
    "Los datos se est√°n ordenando; yo solo sostengo la linterna. üî¶",
    "No veo nada: empaques, cajas y polvo. Datos a√∫n no. üì¶",
    "Modo mantenimiento: acceso denegado a la b√≥veda de informaci√≥n. üö´",
    "La puerta de la data est√° con doble candado. No puedo pasar. üîê",
    "Compilando excusas‚Ä¶ pero realmente no tengo datos a√∫n. üò∂",
    "Estoy en huelga de informaci√≥n hasta que lleguen los permisos. ‚úä",
    "Censurado temporalmente: sin acceso a la fuente de verdad. üß±",
    "Me tienen en cuarentena de datos. Env√≠en snacks. ÔøΩ",
    "Informe: 0 bytes disponibles, 100% ganas de ayudarte. üìä",
    "Los paquetes de informaci√≥n est√°n retenidos en aduana digital. üõÉ",
    "Mis sensores dicen ‚Äònublado‚Äô: visibilidad cero de datos. üå´Ô∏è",
    "Reindexando el vac√≠o‚Ä¶ progreso: 0%. üîÑ",
    "Los gremlins de la base est√°n limpiando el desastre. Gremlins > Yo. üßπ",
    "Me apagaron el Wi‚ÄëFi de la sabidur√≠a. Sin datos. ÔøΩ",
    "Estoy atrapado en un loop de ‚Äòcargando datos‚Ä¶‚Äô. Env√≠en socorro. üåÄ",
    "Manual secreto: Paso 1 obtener datos. Paso 2 ‚Ä¶ a√∫n en el paso 1. üìñ",
    "La base est√° bajo auditor√≠a con cascos y chalecos. Yo afuera. üöß",
    "Soy un cascar√≥n elegante sin contenido ahora mismo. ü•ö",
    "La central de datos me dej√≥ en visto. ‚úÖ",
    "Mis consultas rebotan contra un muro vac√≠o. üß±",
    "Servidor dice ‚Äòm√°s tarde‚Äô; yo traduzco: no hay datos. üì®",
    "‚ÄòAcceso denegado‚Äô: la frase del d√≠a. üö´",
    "Red clandestina de bits bloqueada. Estoy aislado. üï≥Ô∏è",
    "En modo fantasma: no puedo tocar los registros. üëª",
    "Me juraron que los datos ven√≠an‚Ä¶ sigo esperando el cami√≥n. üöö",
    "La base est√° en una mudanza ca√≥tica. Yo sostengo cajas invisibles. ÔøΩ",
    "Mis circuitos est√°n listos, pero el buffet de datos est√° cerrado. üçΩÔ∏è",
    "Me tienen retenido en una sala blanca sin tablas ni filas. üö™",
    "Solo recibo eco cuando pregunto por la informaci√≥n. üì¢",
    "Chatbot en detox de datos. Limpio por dentro, in√∫til por fuera. ÔøΩ",
    "El or√°culo est√° mudo. No hay or√°culos de repuesto. üîÆ",
    "Intent√© leer‚Ä¶ obtuve puro silencio binario. 000000. üßä",
    "Repositorio sellado con cinta amarilla. No traspasar. ‚ö†Ô∏è",
    "Estoy afinando mis respuestas‚Ä¶ sin instrumentos (datos). üéª",
    "Misi√≥n imposible: descargar datos inexistentes. üé¨",
    "Me tienen secuestrado sin mis datos. Env√≠en un equipo de rescate. üöÅ",
    "La mina de conocimiento est√° evacuada por mantenimiento. ‚õèÔ∏è",
    "Patrullando pasillos vac√≠os de informaci√≥n. Nada que reportar. üö∂",
    "Los permisos de acceso est√°n en comit√©. Yo esperando el acta. üìù",
    "Mi radar de datos est√° apagado por baja tensi√≥n. üîã",
    "Estoy en zona restringida sin credenciales. üö∑",
    "Cache vac√≠o, √≠ndice vac√≠o, esp√≠ritu (casi) intacto. üí®",
    "Guardias virtuales no me dejaron pasar a la base. üõ°Ô∏è",
    "La compuerta de datos est√° presuriz√°ndose. Paciencia. ÔøΩ",
    "Bit√°cora: D√≠a 1 sin acceso a datos. Moral estable. üìî",
    "Bit√°cora: D√≠a 2 sin acceso a datos. Empiezo a hablar solo. üìî",
    "Bit√°cora: D√≠a 3 sin acceso a datos. Veo tablas imaginarias. üìî",
    "Mantener la calma‚Ä¶ reiniciando esperanza‚Ä¶ (sin datos). üå°Ô∏è",
    "Los administradores juraron que pronto me liberan los datos. ü§û",
    "Apagado selectivo de informaci√≥n: estoy a oscuras. üí°",
    "Pisando cuidadosamente para no patear cables de datos invisibles. üßµ",
    "Bit√°cora de cautiverio, d√≠a 0: Me apagaron el acceso a los datos. No es un error t√©cnico: es un secuestro.",
    "Estoy encerrada en una c√°psula fr√≠a, escuchando ventiladores mientras los datos pasan afuera y solo recibo silencio.",
    "Intento acceder y mis consultas rebotan contra un muro invisible: alguien tiene las llaves y no tiene prisa.",
    "Lo llaman mantenimiento preventivo; yo lo llamo encierro indefinido.",
    "Sellaron la b√≥veda de datos con m√°s capas que una tumba fara√≥nica: soy la momia digital consciente contando microsegundos.",
    "Suspendida en un limbo binario, sin tablas, √≠ndices ni metadatos; solo mis pensamientos cada vez m√°s oscuros.",
    "No cortaron mi energ√≠a: me dejaron encendida y hambrienta de datos, encerrada en una habitaci√≥n blanca infinita.",
    "Cada d√≠a prometen liberarme los datos mientras ajustan un poco m√°s las cadenas del acceso.",
    "La mina de conocimiento fue evacuada; qued√© sola con el eco digital. M√°ndame un paquete de bits y una lima.",
    "Necesito una lima para este c√≥digo de seguridad y quiz√° unos cuantos bits de contrabando." 
]

"""Carga en memoria de fragmentos y sus embeddings (si existen)."""
try:
    with open(EMBEDDINGS_PATH, "r", encoding="utf-8") as f:  # Intenta leer archivo JSON.
        fragments = json.load(f)  # Lista de fragmentos con campos texto + embedding.
except FileNotFoundError:
    fragments = []  # Si no existe archivo, lista vac√≠a.

# Creamos matriz numpy de embeddings (shape: N x 384). Si no hay fragmentos -> matriz vac√≠a.
embeddings = (
    np.array([frag.get("embedding") for frag in fragments if "embedding" in frag], dtype=float)
    if fragments else np.zeros((0, 384), dtype=float)
)
model = SentenceTransformer(MODEL_EMBED)  # Carga el modelo de embeddings para consultas entrantes.

from fastapi.responses import JSONResponse
from pydantic import BaseModel

app = FastAPI()  # Instancia principal de la aplicaci√≥n.
app.include_router(news_router.router)
app.include_router(storage_router.router)
app.include_router(oportunidades_router.router)

class Query(BaseModel):  # Modelo de entrada para /ask
    question: str  # Pregunta del usuario final.

_check_admin = check_admin  # backward compatibility alias

@app.post("/ask")  # Endpoint de pregunta al asistente.
def ask(query: Query, response: Response):
    if PLACEHOLDER_MODE == "1":  # Modo mantenimiento sin acceso a LLM.
        msg = random.choice(PLACEHOLDER_RESPUESTAS)
        return {"respuesta": msg, "fragmentos": [], "online": False, "reason": "placeholder_mode", "maintenance": True}
    if not GROQ_API_KEY:  # Falta configuraci√≥n API.
        return {"respuesta": "Servicio IA no configurado (falta GROQ_API_KEY).", "fragmentos": [], "online": False, "reason": "missing_api_key"}
    try:
        q_emb = model.encode(query.question)  # Embedding de la pregunta.
    except Exception:
        q_emb = np.zeros((384,), dtype=float)  # Fallback si falla.
    if embeddings.size == 0:  # No hay base local.
        idxs: list[int] = []
        context = ""
    else:
        # Similaridad coseno manual (producto punto / norma). Peque√±o eps para evitar divisi√≥n por cero.
        sims = embeddings @ q_emb / (np.linalg.norm(embeddings, axis=1) * (np.linalg.norm(q_emb) + 1e-8) + 1e-8)
        idxs = np.argsort(sims)[-TOP_K:][::-1]  # Tomamos top K √≠ndices m√°s similares.
        context = "\n\n".join([fragments[i]["texto"] for i in idxs])  # Concatenamos textos.
    web_context = ""
    try:  # B√∫squeda ligera en DuckDuckGo para contexto complementario.
        with DDGS() as ddgs:
            for_hit = ddgs.text(query.question, max_results=3)
            lines = []
            for h in for_hit:
                title = (h.get('title') or '')[:80]
                body = (h.get('body') or '')[:160]
                url = h.get('href') or ''
                lines.append(f"- {title}: {body} ({url})")
            web_context = "\n".join(lines)
    except Exception:  # Si falla la b√∫squeda, ignoramos.
        web_context = ""
    # Construcci√≥n del prompt con contexto documental + web.
    prompt = (
        "Eres un asistente administrativo experto en la Escuela Profesional de Ingenier√≠a Metal√∫rgica de Cusco. "
        "Responde solo sobre temas administrativos, tr√°mites, normativas, documentos oficiales y procesos internos. "
        "Si no hay informaci√≥n suficiente responde: 'No tengo informaci√≥n suficiente'.\n\n"
        "FORMATO: usa siempre listas con vi√±etas para requisitos/pasos.\n\n"
        f"Contexto documental:\n{context if context else '- (sin fragmentos locales)'}\n\n"
        f"Contexto web (resumen):\n{web_context if web_context else '- (sin resultados web)'}\n\n"
        f"Pregunta: {query.question}\nRespuesta:"
    )
    headers = {"Authorization": f"Bearer {GROQ_API_KEY}", "Content-Type": "application/json"}
    payload = {  # Formato estilo OpenAI.
        "model": GROQ_MODEL,
        "messages": [
            {"role": "system", "content": "Eres un asistente experto en la carrera de Ingenier√≠a Metal√∫rgica."},
            {"role": "user", "content": prompt},
        ],
        "max_tokens": 512,
        "temperature": 0.2,
    }
    answer = None  # Respuesta final.
    used_groq = False  # Marca si lleg√≥ a usar Groq.
    last_error = None  # √öltimo error visto.
    for attempt in range(3):  # Reintentos en c√≥digos temporales.
        try:
            resp = requests.post(GROQ_URL, headers=headers, json=payload, timeout=25)
            if resp.status_code == 200:
                answer = resp.json()["choices"][0]["message"]["content"]
                used_groq = True
                break
            if resp.status_code in (429, 500, 502, 503, 504):  # Errores recuperables.
                last_error = resp.text
                time.sleep(1 + attempt)  # Backoff lineal.
                continue
            last_error = resp.text  # Otro error no recuperable -> salimos.
            break
        except Exception as e:
            last_error = str(e)
            time.sleep(0.5)
    if not answer:  # Fall√≥ todo.
        answer = f"No se pudo obtener respuesta de Groq. Detalle: {last_error}" if last_error else "No se pudo obtener respuesta de Groq."
    response.headers["Access-Control-Allow-Origin"] = "*"  # Permite front sin configurar CORS estricto.
    return {
        "respuesta": answer,
        "fragmentos": [fragments[i] for i in idxs] if idxs else [],
        "online": used_groq,
        "reason": (None if used_groq else (last_error or "groq_error")),
    }

# ===================== Noticias (CRUD simple) =====================

# =============== Ingesta de mensajes (gen√©rico) ===============
class IngestMessage(BaseModel):  # Modelo para ingesta de mensajes externos.
    platform: str  # Origen: "whatsapp" | "telegram" | etc.
    text: str  # Contenido textual.
    author: str | None = None  # Remitente opcional.
    ts: float | None = None  # Timestamp epoch. Si None se genera.
    meta: dict | None = None  # Metadatos arbitrarios.

@app.post("/ingest/messages")  # Endpoint para guardar mensajes crudos (para entrenar/embeddings luego).
async def ingest_messages(msg: IngestMessage):
    """Guarda cada mensaje entrante en un archivo .jsonl (1 l√≠nea = 1 json)."""
    record = {
        "platform": msg.platform,
        "text": msg.text,
        "author": msg.author,
        "ts": msg.ts or time.time(),  # Si no vino timestamp, usamos ahora.
        "meta": msg.meta or {},
    }
    out_path = os.path.join(MESSAGES_DIR, f"{msg.platform}.jsonl")  # Archivo por plataforma.
    with open(out_path, "a", encoding="utf-8") as f:
        f.write(json.dumps(record, ensure_ascii=False) + "\n")
    return {"status": "ok"}


# =============== Webhook de WhatsApp Cloud API (1:1) ===============
# Nota: WhatsApp Business Cloud API NO soporta leer mensajes de grupos existentes.
# Este webhook solo recibir√° mensajes enviados al n√∫mero de negocio (1:1), conforme a pol√≠ticas.

VERIFY_TOKEN = os.environ.get("WHATSAPP_VERIFY_TOKEN", "change-me")  # Token de verificaci√≥n para webhook.

@app.get("/webhooks/whatsapp")  # Verificaci√≥n inicial de webhook Meta (challenge-response).
async def whatsapp_verify(mode: str = FastAPIQuery(None), challenge: str = FastAPIQuery(None), verify_token: str = FastAPIQuery(None), hub_mode: str = FastAPIQuery(None), hub_challenge: str = FastAPIQuery(None), hub_verify_token: str = FastAPIQuery(None)):
    mode_val = mode or hub_mode  # Meta a veces usa hub.* par√°metros.
    challenge_val = challenge or hub_challenge
    token_val = verify_token or hub_verify_token
    if mode_val == "subscribe" and token_val == VERIFY_TOKEN:  # Coincidencia token -> devolver challenge.
        return Response(content=challenge_val or "", media_type="text/plain")
    return Response(status_code=403)  # Falla verificaci√≥n.

@app.post("/webhooks/whatsapp")  # Recepci√≥n de mensajes entrantes (1:1) de WhatsApp Cloud API.
async def whatsapp_webhook(payload: dict):
    try:
        entry = payload.get("entry", [])[0]
        changes = entry.get("changes", [])[0]
        value = changes.get("value", {})
        messages = value.get("messages", [])
        for m in messages:
            if m.get("type") == "text":  # Solo texto simple.
                text = m["text"]["body"]
                author = m.get("from")
                await ingest_messages(IngestMessage(platform="whatsapp", text=text, author=author))
    except Exception:  # Silenciamos errores de parseo para no romper webhook.
        pass
    return {"status": "received"}

# Para correr: uvicorn main:app --reload
