"""
Limpiador Especializado para Documentos Legales
Estrategia basada en la estructura jerÃ¡rquica especÃ­fica de documentos jurÃ­dicos
"""

import json
import re
from typing import List, Dict, Any, Optional

class LegalDocumentCleaner:
    """
    Limpiador especializado que respeta la estructura jerÃ¡rquica de documentos legales:
    - ArtÃ­culos como unidad base (ArtÃ­culo XÂ° + tÃ­tulo + contenido)
    - CapÃ­tulos como agrupadores superiores
    - TÃ­tulos como divisores principales
    """
    
    def __init__(self):
        # Patrones especÃ­ficos para documentos legales
        self.article_pattern = re.compile(r'^ArtÃ­culo\s+\d+[Â°Âº]\s*', re.IGNORECASE)  # Removido $ para permitir tÃ­tulos
        self.chapter_pattern = re.compile(r'^(CAPÃTULO|CapÃ­tulo)\s+[IVX\d]+', re.IGNORECASE)
        self.title_pattern = re.compile(r'^(TÃTULO|TÃ­tulo)\s+[IVX\d]+', re.IGNORECASE)
        
        # ConfiguraciÃ³n especÃ­fica para fuentes y formatos
        self.article_font = "Arial-BoldMT"  # ArtÃ­culos en negritas
        self.content_font = "ArialMT"       # Contenido normal
        
    def clean_document(self, json_file_path: str) -> Dict[str, Any]:
        """Limpia un documento legal respetando su estructura jerÃ¡rquica"""
        
        with open(json_file_path, 'r', encoding='utf-8') as f:
            raw_data = json.load(f)
        
        # Filtrar elementos vacÃ­os y muy pequeÃ±os
        content_items = [item for item in raw_data['content'] 
                        if item['text'].strip() and len(item['text'].strip()) > 1]
        
        print(f"ğŸ“„ Procesando: {raw_data['file']}")
        print(f"ğŸ“Š Elementos originales: {len(raw_data['content'])}")
        print(f"ğŸ“Š Elementos filtrados: {len(content_items)}")
        
        # Agrupar artÃ­culos usando la estructura especÃ­fica
        articles = self._extract_articles(content_items)
        
        print(f"ğŸ“Š ArtÃ­culos detectados: {len(articles)}")
        
        # Crear chunks finales optimizados para RAG
        final_chunks = self._create_rag_chunks(articles)
        
        return {
            "source_file": raw_data['file'],
            "total_chunks": len(final_chunks),
            "chunks": final_chunks,
            "metadata": {
                "original_spans": len(raw_data['content']),
                "filtered_spans": len(content_items),
                "extracted_articles": len(articles),
                "final_chunks": len(final_chunks),
                "processing_method": "legal_document_cleaner_v1"
            }
        }
    
    def _extract_articles(self, content_items: List[Dict]) -> List[Dict]:
        """Extrae artÃ­culos completos respetando la estructura jerÃ¡rquica"""
        
        articles = []
        current_article = None
        current_context = {
            "chapter": "",
            "title": "",
            "section": ""
        }
        
        i = 0
        while i < len(content_items):
            item = content_items[i]
            text = item['text'].strip()
            font = item.get('font', '')
            size = item.get('size', 0)
            
            # Actualizar contexto jerÃ¡rquico - mejorado para detectar tÃ­tulos
            if self._is_title_start(text, font, size):
                # Capturar tÃ­tulo completo que puede estar en mÃºltiples lÃ­neas
                title_text = text
                j = i + 1
                # Buscar la lÃ­nea siguiente para completar el tÃ­tulo
                while j < len(content_items) and j < i + 3:  # MÃ¡ximo 3 lÃ­neas para el tÃ­tulo
                    next_item = content_items[j]
                    next_text = next_item['text'].strip()
                    next_font = next_item.get('font', '')
                    next_size = next_item.get('size', 0)
                    
                    # Si la siguiente lÃ­nea es parte del tÃ­tulo (mismo formato)
                    if (next_font == font and abs(next_size - size) < 1 and 
                        not self._is_chapter(next_text) and 
                        not self._is_article_start(next_text, next_font)):
                        title_text += " " + next_text
                        j += 1
                    else:
                        break
                
                current_context['title'] = title_text
                current_context['chapter'] = ""
                current_context['section'] = ""
                i = j - 1  # Ajustar Ã­ndice para continuar despuÃ©s del tÃ­tulo completo
                
            elif self._is_chapter(text):
                current_context['chapter'] = text
                current_context['section'] = ""
            elif self._is_section_header(text, item):
                current_context['section'] = text
            
            # Detectar inicio de artÃ­culo
            if self._is_article_start(text, font):
                # Guardar artÃ­culo anterior si existe
                if current_article:
                    articles.append(current_article)
                
                # Nuevo artÃ­culo
                current_article = {
                    "article_number": text,
                    "article_title": "",
                    "content": "",
                    "full_text": text,
                    "context": current_context.copy(),
                    "word_count": 0,
                    "spans": [item]
                }
                
                # Buscar tÃ­tulo del artÃ­culo (primera lÃ­nea despuÃ©s del nÃºmero)
                if i + 1 < len(content_items):
                    next_item = content_items[i + 1]
                    next_text = next_item['text'].strip()
                    
                    # Si la siguiente lÃ­nea no es otro artÃ­culo, es probablemente el tÃ­tulo/contenido
                    if not self._is_article_start(next_text, next_item.get('font', '')):
                        # Determinar si es tÃ­tulo (primera lÃ­nea significativa)
                        if len(next_text) < 200 and not next_text.endswith('.'):
                            current_article['article_title'] = next_text
                            current_article['full_text'] += " " + next_text
                            current_article['spans'].append(next_item)
                            i += 1  # Saltar esta lÃ­nea en la prÃ³xima iteraciÃ³n
                
            elif current_article and not self._is_article_start(text, font):
                # Agregar contenido al artÃ­culo actual
                if current_article['content']:
                    current_article['content'] += " " + text
                else:
                    current_article['content'] = text
                
                current_article['full_text'] += " " + text
                current_article['spans'].append(item)
                current_article['word_count'] = len(current_article['full_text'].split())
            
            i += 1
        
        # Agregar Ãºltimo artÃ­culo
        if current_article:
            articles.append(current_article)
        
        return articles
    
    def _is_article_start(self, text: str, font: str) -> bool:
        """Detecta si es el inicio de un artÃ­culo basÃ¡ndose en patrÃ³n y formato"""
        return (
            self.article_pattern.match(text) and 
            font == self.article_font
        )
    
    def _is_chapter(self, text: str) -> bool:
        """Detecta capÃ­tulos"""
        return bool(self.chapter_pattern.match(text))
    
    def _is_title(self, text: str) -> bool:
        """Detecta tÃ­tulos"""
        return bool(self.title_pattern.match(text))
    
    def _is_title_start(self, text: str, font: str, size: float) -> bool:
        """Detecta inicio de tÃ­tulo basÃ¡ndose en patrÃ³n, formato y tamaÃ±o"""
        return (
            self.title_pattern.match(text) and 
            font == "Arial-BoldMT" and 
            size > 13  # Los tÃ­tulos tienen tamaÃ±o ~14.04
        )
    
    def _is_section_header(self, text: str, item: Dict) -> bool:
        """Detecta encabezados de secciÃ³n"""
        return (
            len(text) < 200 and 
            text.isupper() and
            item.get('size', 0) > 12
        )
    
    def _create_rag_chunks(self, articles: List[Dict]) -> List[Dict]:
        """Crea chunks optimizados para RAG manteniendo artÃ­culos completos"""
        
        chunks = []
        
        for article in articles:
            # Crear chunk por artÃ­culo completo
            chunk = {
                "content": article['full_text'],
                "article_number": article['article_number'],
                "article_title": article['article_title'],
                "article_content": article['content'],
                "context": article['context'],
                "word_count": article['word_count'],
                "type": "article",
                "metadata": {
                    "chapter": article['context']['chapter'],
                    "title": article['context']['title'],
                    "section": article['context']['section'],
                    "spans_count": len(article['spans'])
                }
            }
            
            # Si el artÃ­culo es muy largo (>800 palabras), considerar dividirlo
            if article['word_count'] > 800:
                # Mantener como un solo chunk pero marcar para revisiÃ³n
                chunk['metadata']['requires_review'] = True
                chunk['metadata']['reason'] = 'long_article'
            
            chunks.append(chunk)
        
        return chunks
    
    def preview_articles(self, json_file_path: str, limit: int = 5) -> None:
        """Vista previa de los primeros artÃ­culos detectados"""
        
        with open(json_file_path, 'r', encoding='utf-8') as f:
            raw_data = json.load(f)
        
        content_items = [item for item in raw_data['content'] 
                        if item['text'].strip() and len(item['text'].strip()) > 1]
        
        articles = self._extract_articles(content_items)
        
        print(f"\nğŸ” VISTA PREVIA - Primeros {min(limit, len(articles))} artÃ­culos:")
        print("=" * 80)
        
        for i, article in enumerate(articles[:limit]):
            print(f"\nğŸ“„ ARTÃCULO {i+1}:")
            print(f"   NÃºmero: {article['article_number']}")
            print(f"   TÃ­tulo: {article['article_title']}")
            print(f"   Contexto: {article['context']['chapter']}")
            print(f"   Palabras: {article['word_count']}")
            print(f"   Contenido: {article['content'][:150]}...")
            print("-" * 40)

def main():
    """Procesar documentos legales con el nuevo limpiador especializado"""
    import os
    
    cleaner = LegalDocumentCleaner()
    
    # Crear carpeta de salida
    os.makedirs("output", exist_ok=True)
    
    # Procesar documentos
    input_folder = "../data_ingest/output"
    processed_files = [f for f in os.listdir(input_folder) if f.endswith("_processed.json")]
    
    for json_filename in processed_files:
        json_file = os.path.join(input_folder, json_filename)
        print(f"\nğŸ”„ Procesando con nueva estrategia: {json_filename}")
        
        try:
            # Vista previa primero
            print("\nğŸ“‹ VISTA PREVIA:")
            cleaner.preview_articles(json_file, limit=3)
            
            # Procesamiento completo
            print("\nâš™ï¸ PROCESAMIENTO COMPLETO:")
            cleaned_doc = cleaner.clean_document(json_file)
            
            # Guardar resultado
            output_filename = json_filename.replace("_processed.json", "_legal_cleaned.json")
            output_file = os.path.join("output", output_filename)
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(cleaned_doc, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… Guardado: {output_file}")
            print(f"   ğŸ“Š ArtÃ­culos: {cleaned_doc['metadata']['extracted_articles']}")
            print(f"   ğŸ“Š Chunks finales: {cleaned_doc['total_chunks']}")
            
            # Buscar y mostrar el ArtÃ­culo 97Â° especÃ­ficamente
            if "Estatuto" in json_filename:
                print(f"\nğŸ¯ Verificando ArtÃ­culo 97Â°...")
                for i, chunk in enumerate(cleaned_doc['chunks']):
                    if 'ArtÃ­culo 97Â°' in chunk['content']:
                        print(f"âœ… Encontrado en chunk {i+1}:")
                        print(f"   NÃºmero: {chunk['article_number']}")
                        print(f"   TÃ­tulo: {chunk['article_title']}")
                        print(f"   Contenido completo: {chunk['article_content']}")
                        print(f"   Palabras: {chunk['word_count']}")
                        break
                        
        except Exception as e:
            print(f"âŒ Error: {e}")
            import traceback
            traceback.print_exc()
    
    print(f"\nğŸ‰ Â¡Procesamiento con estrategia legal completado!")

if __name__ == "__main__":
    main()
