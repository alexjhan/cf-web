"""
Test directo del algoritmo _extract_articles para encontrar d√≥nde est√° el problema
"""

from legal_document_cleaner import LegalDocumentCleaner
import json

def main():
    cleaner = LegalDocumentCleaner()
    
    # Cargar datos originales
    with open('../data_ingest/output/EstatutoUniversitario_UNSAAC_processed.json', 'r', encoding='utf-8') as f:
        raw_data = json.load(f)

    content_items = [item for item in raw_data['content'] 
                    if item['text'].strip() and len(item['text'].strip()) > 1]

    print('üîç TEST DIRECTO DEL ALGORITMO _extract_articles')
    print('=' * 60)
    
    # Crear una versi√≥n modificada del algoritmo que imprima debug info
    print('üìä Informaci√≥n b√°sica:')
    print(f'  Total de elementos filtrados: {len(content_items)}')
    
    # Buscar espec√≠ficamente el √°rea del T√çTULO I
    titulo_i_index = None
    for i, item in enumerate(content_items):
        text = item['text'].strip()
        font = item.get('font', '')
        size = item.get('size', 0)
        if text == "T√çTULO I" and size > 13:
            titulo_i_index = i
            break
    
    print(f'  T√çTULO I encontrado en √≠ndice: {titulo_i_index}')
    
    # Simular el algoritmo desde el T√çTULO I
    if titulo_i_index:
        print(f'\nüéØ SIMULANDO ALGORITMO DESDE T√çTULO I (√≠ndice {titulo_i_index}):')
        
        current_context = {
            "chapter": "",
            "title": "",
            "section": ""
        }
        
        articles_found = []
        
        # Procesar desde el T√çTULO I hasta encontrar algunos art√≠culos
        for i in range(titulo_i_index, min(titulo_i_index + 50, len(content_items))):
            item = content_items[i]
            text = item['text'].strip()
            font = item.get('font', '')
            size = item.get('size', 0)
            
            # Detectar t√≠tulos
            if cleaner._is_title_start(text, font, size):
                # Capturar t√≠tulo completo
                title_text = text
                j = i + 1
                while j < len(content_items) and j < i + 3:
                    next_item = content_items[j]
                    next_text = next_item['text'].strip()
                    next_font = next_item.get('font', '')
                    next_size = next_item.get('size', 0)
                    
                    if (next_font == font and abs(next_size - size) < 1 and 
                        not cleaner._is_chapter(next_text) and 
                        not cleaner._is_article_start(next_text, next_font)):
                        title_text += " " + next_text
                        j += 1
                    else:
                        break
                
                current_context['title'] = title_text
                print(f'  üìñ T√çTULO detectado: "{title_text}"')
                
            # Detectar cap√≠tulos
            elif cleaner._is_chapter(text):
                current_context['chapter'] = text
                print(f'  üìÅ CAP√çTULO detectado: "{text}"')
                
            # Detectar art√≠culos
            elif cleaner._is_article_start(text, font):
                articles_found.append({
                    'index': i,
                    'number': text,
                    'context': current_context.copy()
                })
                print(f'  üìÑ ART√çCULO detectado: "{text}"')
                print(f'      Contexto: T√≠tulo="{current_context["title"]}", Cap√≠tulo="{current_context["chapter"]}"')
                
                if len(articles_found) >= 5:  # Limitar a 5 art√≠culos para el test
                    break
        
        print(f'\n‚úÖ RESULTADO DEL TEST:')
        print(f'  Art√≠culos encontrados: {len(articles_found)}')
        
        for i, art in enumerate(articles_found):
            print(f'  {i+1}. {art["number"]} - T√≠tulo: "{art["context"]["title"]}"')

if __name__ == "__main__":
    main()
